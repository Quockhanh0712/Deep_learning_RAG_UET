# üìò T√†i li·ªáu H·ªá th·ªëng RAG Chatbot (BGE-M3 + ChromaDB + Gemini/Ollama)

## 1. Gi·ªõi thi·ªáu

H·ªá th·ªëng **RAG Chatbot** l√† m·ªôt gi·∫£i ph√°p m√£ ngu·ªìn m·ªü cho ph√©p ng∆∞·ªùi d√πng x√¢y d·ª±ng tr·ª£ l√Ω AI c√° nh√¢n c√≥ kh·∫£ nƒÉng tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n d·ªØ li·ªáu ri√™ng (PDF, TXT). H·ªá th·ªëng s·ª≠ d·ª•ng k·ªπ thu·∫≠t **Retrieval-Augmented Generation (RAG)** ƒë·ªÉ k·∫øt h·ª£p s·ª©c m·∫°nh t√¨m ki·∫øm ng·ªØ nghƒ©a (Semantic Search) v·ªõi kh·∫£ nƒÉng sinh ng·ªØ c·ªßa c√°c m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn (LLM).

### T√≠nh nƒÉng ch√≠nh
- **ƒêa m√¥ h√¨nh LLM**: H·ªó tr·ª£ linh ho·∫°t gi·ªØa **Google Gemini** (Cloud, mi·ªÖn ph√≠/tr·∫£ ph√≠) v√† **Ollama** (Local, ri√™ng t∆∞).
- **Embedding m·∫°nh m·∫Ω**: S·ª≠ d·ª•ng **BAAI/bge-m3** (ho·∫∑c bge-large) cho kh·∫£ nƒÉng hi·ªÉu ƒëa ng√¥n ng·ªØ v√† ti·∫øng Vi·ªát v∆∞·ª£t tr·ªôi.
- **C∆° s·ªü d·ªØ li·ªáu Vector**: T√≠ch h·ª£p **ChromaDB** ƒë·ªÉ l∆∞u tr·ªØ v√† truy xu·∫•t d·ªØ li·ªáu hi·ªáu nƒÉng cao.
- **Giao di·ªán ƒëa d·∫°ng**: Cung c·∫•p 3 t√πy ch·ªçn giao di·ªán: **Chainlit** (Chat chuy√™n nghi·ªáp), **Gradio** (Web UI ƒë∆°n gi·∫£n), v√† **Streamlit** (Dashboard).
- **T·ªëi ∆∞u h√≥a GPU**: H·ªó tr·ª£ tƒÉng t·ªëc GPU (CUDA) v√† t√≠nh to√°n FP16 cho t·ªëc ƒë·ªô x·ª≠ l√Ω nhanh.

---

## 2. Ki·∫øn tr√∫c H·ªá th·ªëng

H·ªá th·ªëng ho·∫°t ƒë·ªông theo quy tr√¨nh kh√©p k√≠n g·ªìm 4 giai ƒëo·∫°n:

1.  **Ingestion (N·∫°p d·ªØ li·ªáu)**
    -   **Input**: File PDF ho·∫∑c TXT t·ª´ ng∆∞·ªùi d√πng.
    -   **Processing**: ƒê·ªçc n·ªôi dung -> Chia nh·ªè (Chunking) th√†nh c√°c ƒëo·∫°n vƒÉn b·∫£n (m·∫∑c ƒë·ªãnh 500 t·ª´).
    -   **Embedding**: Chuy·ªÉn ƒë·ªïi vƒÉn b·∫£n th√†nh vector s·ªë h·ªçc s·ª≠ d·ª•ng m√¥ h√¨nh BGE.
    -   **Storage**: L∆∞u vector v√† metadata v√†o ChromaDB.

2.  **Retrieval (Truy xu·∫•t)**
    -   **Query**: Ng∆∞·ªùi d√πng ƒë·∫∑t c√¢u h·ªèi.
    -   **Search**: H·ªá th·ªëng t√¨m ki·∫øm `k` ƒëo·∫°n vƒÉn b·∫£n (Chunks) c√≥ n·ªôi dung t∆∞∆°ng ƒë·ªìng nh·∫•t v·ªõi c√¢u h·ªèi trong ChromaDB.

3.  **Generation (Sinh c√¢u tr·∫£ l·ªùi)**
    -   **Prompting**: Gh√©p c√¢u h·ªèi v√† c√°c ƒëo·∫°n vƒÉn b·∫£n t√¨m ƒë∆∞·ª£c v√†o m·ªôt khu√¥n m·∫´u (Prompt).
    -   **Inference**: G·ª≠i Prompt ƒë·∫øn LLM (Gemini ho·∫∑c Ollama) ƒë·ªÉ sinh c√¢u tr·∫£ l·ªùi.

4.  **Response (Ph·∫£n h·ªìi)**
    -   Hi·ªÉn th·ªã c√¢u tr·∫£ l·ªùi cu·ªëi c√πng k√®m theo ngu·ªìn tham kh·∫£o (Source citations).

---

## 3. C√†i ƒë·∫∑t v√† Tri·ªÉn khai

### Y√™u c·∫ßu h·ªá th·ªëng
- **OS**: Windows, Linux, ho·∫∑c macOS.
- **Python**: Phi√™n b·∫£n 3.10 tr·ªü l√™n.
- **Ph·∫ßn c·ª©ng**:
    -   CPU: T·ªëi thi·ªÉu 4 cores.
    -   RAM: 8GB (16GB n·∫øu ch·∫°y Ollama local).
    -   GPU (Khuy·∫øn ngh·ªã): NVIDIA GPU v·ªõi VRAM >= 4GB ƒë·ªÉ tƒÉng t·ªëc Embedding v√† Ollama.

### C√°c b∆∞·ªõc c√†i ƒë·∫∑t

1.  **Clone m√£ ngu·ªìn**
    ```bash
    git clone <repository_url>
    cd rag-bge-chroma-gemini
    ```

2.  **T·∫°o m√¥i tr∆∞·ªùng ·∫£o (Virtual Environment)**
    ```powershell
    # Windows PowerShell
    python -m venv .venv
    .\.venv\Scripts\Activate.ps1
    ```

3.  **C√†i ƒë·∫∑t th∆∞ vi·ªán ph·ª• thu·ªôc**
    ```bash
    pip install -r requirements.txt
    ```
    *L∆∞u √Ω: N·∫øu d√πng GPU, h√£y ƒë·∫£m b·∫£o ƒë√£ c√†i ƒë·∫∑t PyTorch phi√™n b·∫£n h·ªó tr·ª£ CUDA.*

4.  **C·∫•u h√¨nh m√¥i tr∆∞·ªùng**
    T·∫°o file `.env` t·∫°i th∆∞ m·ª•c g·ªëc (tham kh·∫£o m·ª•c 4).

---

## 4. C·∫•u h√¨nh Chi ti·∫øt (.env)

T·∫°o file `.env` v√† t√πy ch·ªânh c√°c tham s·ªë sau:

### C·∫•u h√¨nh LLM (Ch·ªçn 1 trong 2)

**Option 1: Google Gemini (Cloud)**
```env
LLM_PROVIDER=gemini
GOOGLE_API_KEY=AIzaSy...  # API Key t·ª´ Google AI Studio
GEMINI_MODEL=gemini-1.5-flash
```

**Option 2: Ollama (Local)**
```env
LLM_PROVIDER=ollama
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:3b  # Ho·∫∑c model kh√°c ƒë√£ pull v·ªÅ
```

### C·∫•u h√¨nh Embedding & Vector Store
```env
# M√¥ h√¨nh Embedding (Khuy√™n d√πng BAAI/bge-m3 cho ti·∫øng Vi·ªát)
EMBEDDING_MODEL=BAAI/bge-m3

# C·∫•u h√¨nh hi·ªáu nƒÉng
EMBEDDING_BATCH_SIZE=16  # Gi·∫£m xu·ªëng 8 ho·∫∑c 4 n·∫øu b·ªã l·ªói Out of Memory
USE_FP16=true            # True ƒë·ªÉ tƒÉng t·ªëc tr√™n GPU

# ƒê∆∞·ªùng d·∫´n l∆∞u d·ªØ li·ªáu ChromaDB
CHROMA_PATH=./data/chroma_db
COLLECTION_NAME=documents
```

### C·∫•u h√¨nh RAG
```env
# S·ªë l∆∞·ª£ng ƒëo·∫°n vƒÉn b·∫£n l·∫•y l√†m ng·ªØ c·∫£nh
TOP_K=5
```

---

## 5. H∆∞·ªõng d·∫´n S·ª≠ d·ª•ng

### 5.1. Giao di·ªán Chainlit (Khuy√™n d√πng)
Giao di·ªán chat hi·ªán ƒë·∫°i, h·ªó tr·ª£ streaming v√† tr·∫£i nghi·ªám ng∆∞·ªùi d√πng t·ªët nh·∫•t.

- **Kh·ªüi ch·∫°y**:
  ```powershell
  chainlit run chatbot.py -w
  ```
- **Truy c·∫≠p**: `http://localhost:8000`
- **T√≠nh nƒÉng**:
  - **Upload**: K√©o th·∫£ file ho·∫∑c click icon üìé.
  - **L·ªánh Chat**:
    - `/files`: Xem danh s√°ch t√†i li·ªáu.
    - `/clear`: X√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i.
    - `/delete <file_id>`: X√≥a t√†i li·ªáu c·ª• th·ªÉ.
    - `/help`: Xem h∆∞·ªõng d·∫´n.

### 5.2. Giao di·ªán Gradio
Giao di·ªán ƒë∆°n gi·∫£n, tr·ª±c quan, th√≠ch h·ª£p ƒë·ªÉ demo nhanh.

- **Kh·ªüi ch·∫°y**:
  ```powershell
  python app_gradio.py
  ```
- **Truy c·∫≠p**: `http://localhost:7860`
- **T√≠nh nƒÉng**: Tab qu·∫£n l√Ω file ri√™ng bi·ªát, xem tr∆∞·ªõc ngu·ªìn tham kh·∫£o r√µ r√†ng.

### 5.3. Giao di·ªán Streamlit
Giao di·ªán d·∫°ng Dashboard, d·ªÖ d√†ng t√πy bi·∫øn layout.

- **Kh·ªüi ch·∫°y**:
  ```powershell
  streamlit run app_modern.py
  ```
- **Truy c·∫≠p**: `http://localhost:8501`

---

## 6. Chi ti·∫øt K·ªπ thu·∫≠t (Source Code)

### `src/embeddings.py`
- Qu·∫£n l√Ω model `SentenceTransformer`.
- T·ª± ƒë·ªông ph√°t hi·ªán GPU/CPU.
- `embed_texts`: H√†m x·ª≠ l√Ω embedding theo batch ƒë·ªÉ t·ªëi ∆∞u hi·ªáu nƒÉng.
- `ChromaEmbeddingFunction`: Wrapper ƒë·ªÉ t√≠ch h·ª£p v·ªõi ChromaDB.

### `src/file_manager.py`
- `load_file`: ƒê·ªçc file PDF/TXT, chia nh·ªè vƒÉn b·∫£n (chunking) v√† g·ªçi h√†m l∆∞u v√†o DB.
- `_chunk_text`: Thu·∫≠t to√°n chia vƒÉn b·∫£n d·ª±a tr√™n s·ªë l∆∞·ª£ng t·ª´ (word-based sliding window).

### `src/llm_client.py`
- L·ªõp tr·ª´u t∆∞·ª£ng h√≥a vi·ªác g·ªçi LLM.
- T·ª± ƒë·ªông chuy·ªÉn ƒë·ªïi gi·ªØa `genai.Client` (Gemini) v√† `ollama.chat` d·ª±a tr√™n c·∫•u h√¨nh.

### `src/vector_store.py`
- Qu·∫£n l√Ω k·∫øt n·ªëi `chromadb.PersistentClient`.
- C√°c h√†m CRUD: `add_documents`, `query_documents`, `delete_by_file_id`, `list_files`.

---

## 7. X·ª≠ l√Ω S·ª± c·ªë (Troubleshooting)

| V·∫•n ƒë·ªÅ | Nguy√™n nh√¢n | Gi·∫£i ph√°p |
|--------|-------------|-----------|
| **L·ªói `ModuleNotFoundError`** | Ch∆∞a k√≠ch ho·∫°t venv ho·∫∑c thi·∫øu th∆∞ vi·ªán | Ch·∫°y `.\.venv\Scripts\Activate.ps1` v√† `pip install -r requirements.txt` |
| **L·ªói `CUDA out of memory`** | GPU h·∫øt VRAM khi embedding | Gi·∫£m `EMBEDDING_BATCH_SIZE` trong `.env` xu·ªëng 8 ho·∫∑c 4. |
| **Chainlit kh√¥ng ch·∫°y** | L·ªói ƒë∆∞·ªùng d·∫´n ho·∫∑c bi·∫øn m√¥i tr∆∞·ªùng | Th·ª≠ ch·∫°y `python -m chainlit run chatbot.py -w` |
| **Ollama connection refused** | Ollama ch∆∞a ch·∫°y | M·ªü ·ª©ng d·ª•ng Ollama ho·∫∑c ch·∫°y `ollama serve` trong terminal kh√°c. |
| **K·∫øt qu·∫£ tr·∫£ l·ªùi kh√¥ng li√™n quan** | `TOP_K` th·∫•p ho·∫∑c d·ªØ li·ªáu k√©m | TƒÉng `TOP_K` l√™n 7-10 ho·∫∑c ki·ªÉm tra ch·∫•t l∆∞·ª£ng file upload. |

---

## 8. M·ªü r·ªông & Ph√°t tri·ªÉn

ƒê·ªÉ t√πy ch·ªânh h·ªá th·ªëng:
1.  **Th√™m ƒë·ªãnh d·∫°ng file**: S·ª≠a `src/file_manager.py` ƒë·ªÉ h·ªó tr·ª£ `.docx`, `.html`.
2.  **Thay ƒë·ªïi Prompt**: S·ª≠a h√†m `build_prompt` trong `src/rag_pipeline.py` ho·∫∑c `chatbot.py`.
3.  **T√πy ch·ªânh UI**:
    -   Chainlit: S·ª≠a `.chainlit/config.toml` v√† `chatbot.py`.
    -   Gradio: S·ª≠a `custom_css` trong `app_gradio.py`.

---
*T√†i li·ªáu h·ªá th·ªëng phi√™n b·∫£n 2.0 - C·∫≠p nh·∫≠t ng√†y 02/12/2025*
