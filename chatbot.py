"""
Professional RAG Chatbot Interface using Chainlit
A modern, fast, and beautiful chatbot UI for RAG-based Q&A
"""

import os
from pathlib import Path
from typing import List, Optional
import asyncio

import chainlit as cl
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

from src.file_manager import load_file, delete_file
from src.vector_store import list_files, query_documents
from src.llm_client import generate_answer

# Configuration
UPLOAD_DIR = Path("data/uploads")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
TOP_K = int(os.getenv("TOP_K", "5"))


def build_prompt(question: str, docs: List[str]) -> str:
    """Build the prompt for the LLM."""
    context = "\n\n".join(docs)
    prompt = (
        "Báº¡n lÃ  trá»£ lÃ½ AI thÃ´ng minh vÃ  thÃ¢n thiá»‡n. "
        "Tráº£ lá»i chi tiáº¿t, chÃ­nh xÃ¡c vÃ  dá»… hiá»ƒu dá»±a trÃªn ngá»¯ cáº£nh Ä‘Æ°á»£c cung cáº¥p.\n"
        "Náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p, hÃ£y thÃ´ng bÃ¡o ráº±ng báº¡n khÃ´ng cÃ³ Ä‘á»§ thÃ´ng tin.\n\n"
        f"ğŸ“š Ngá»¯ cáº£nh:\n{context}\n\n"
        f"â“ CÃ¢u há»i: {question}\n\n"
        "ğŸ’¡ Tráº£ lá»i:"
    )
    return prompt


def sync_process_query(question: str) -> dict:
    """Process a question and return the answer with context."""
    # Query documents
    res = query_documents(question, k=TOP_K)
    docs = res["documents"][0]
    metadatas = res["metadatas"][0]
    
    # Build prompt and generate answer
    prompt = build_prompt(question, docs)
    answer = generate_answer(prompt)
    
    return {
        "answer": answer,
        "context": docs,
        "metadatas": metadatas,
    }


async def process_uploaded_file(file_path: str, file_name: str) -> str:
    """Process an uploaded file and add to vector store."""
    # Save to uploads directory
    save_path = UPLOAD_DIR / file_name
    
    # Copy file
    with open(file_path, "rb") as src:
        content = src.read()
    with open(save_path, "wb") as dst:
        dst.write(content)
    
    # Check if already loaded
    existing_files = list_files()
    already_loaded = any(fid.startswith(file_name + "-") for fid in existing_files)
    
    if already_loaded:
        return f"â„¹ï¸ File `{file_name}` Ä‘Ã£ Ä‘Æ°á»£c náº¡p trÆ°á»›c Ä‘Ã³."
    
    # Load file into vector store
    file_id = await asyncio.to_thread(load_file, str(save_path))
    return f"âœ… ÄÃ£ náº¡p file thÃ nh cÃ´ng!\n- **File:** `{file_name}`\n- **ID:** `{file_id}`"


@cl.on_chat_start
async def on_chat_start():
    """Initialize the chat session."""
    # Set session variables
    cl.user_session.set("history", [])
    
    # Get list of loaded files
    files = list_files()
    
    # Welcome message
    welcome_msg = """# ğŸ¤– RAG Chatbot

Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ AI Ä‘Æ°á»£c há»— trá»£ bá»Ÿi **BGE Embeddings** + **ChromaDB** + **Gemini/Ollama**.

## ğŸ“‹ TÃ i liá»‡u Ä‘Ã£ náº¡p:
"""
    
    if files:
        for f in files:
            welcome_msg += f"- ğŸ“„ `{f}`\n"
    else:
        welcome_msg += "_ChÆ°a cÃ³ tÃ i liá»‡u nÃ o Ä‘Æ°á»£c náº¡p._\n"
    
    welcome_msg += """
---
**ğŸ’¡ HÆ°á»›ng dáº«n:**
- Äáº·t cÃ¢u há»i vá» ná»™i dung tÃ i liá»‡u Ä‘Ã£ náº¡p
- ÄÃ­nh kÃ¨m file PDF/TXT cÃ¹ng vá»›i tin nháº¯n Ä‘á»ƒ upload
- Nháº­p `/files` Ä‘á»ƒ xem danh sÃ¡ch tÃ i liá»‡u
- Nháº­p `/clear` Ä‘á»ƒ xÃ³a lá»‹ch sá»­ chat
- Nháº­p `/delete <file_id>` Ä‘á»ƒ xÃ³a tÃ i liá»‡u

HÃ£y Ä‘áº·t cÃ¢u há»i cá»§a báº¡n! ğŸš€
"""
    
    await cl.Message(content=welcome_msg).send()


@cl.on_message
async def on_message(message: cl.Message):
    """Handle incoming messages."""
    user_input = message.content.strip()
    
    # Handle file attachments first
    if message.elements:
        for element in message.elements:
            if hasattr(element, 'path') and element.path:
                file_name = getattr(element, 'name', os.path.basename(element.path))
                # Check file extension
                if file_name.lower().endswith(('.pdf', '.txt')):
                    await cl.Message(content=f"â³ Äang xá»­ lÃ½ file `{file_name}`...").send()
                    try:
                        result = await process_uploaded_file(element.path, file_name)
                        await cl.Message(content=result).send()
                    except Exception as e:
                        await cl.Message(content=f"âŒ Lá»—i khi náº¡p file: {str(e)}").send()
                else:
                    await cl.Message(content=f"âš ï¸ Chá»‰ há»— trá»£ file PDF vÃ  TXT. File `{file_name}` bá»‹ bá» qua.").send()
        
        # If only file upload, no question
        if not user_input:
            return
    
    # Handle special commands
    if user_input.lower() == "/files":
        files = list_files()
        if files:
            file_list = "\n".join([f"ğŸ“„ `{f}`" for f in files])
            await cl.Message(content=f"## ğŸ“š TÃ i liá»‡u Ä‘Ã£ náº¡p:\n{file_list}").send()
        else:
            await cl.Message(content="ğŸ“­ ChÆ°a cÃ³ tÃ i liá»‡u nÃ o Ä‘Æ°á»£c náº¡p.").send()
        return
    
    if user_input.lower() == "/clear":
        cl.user_session.set("history", [])
        await cl.Message(content="ğŸ§¹ ÄÃ£ xÃ³a lá»‹ch sá»­ chat!").send()
        return
    
    if user_input.lower() == "/help":
        help_msg = """## ğŸ“– Trá»£ giÃºp

**Commands:**
- `/files` - Xem danh sÃ¡ch tÃ i liá»‡u Ä‘Ã£ náº¡p
- `/delete <file_id>` - XÃ³a tÃ i liá»‡u
- `/clear` - XÃ³a lá»‹ch sá»­ chat
- `/help` - Hiá»ƒn thá»‹ trá»£ giÃºp

**Upload file:**
- Click vÃ o icon ğŸ“ Ä‘á»ƒ Ä‘Ã­nh kÃ¨m file PDF/TXT

**Há»i Ä‘Ã¡p:**
- Nháº­p cÃ¢u há»i liÃªn quan Ä‘áº¿n tÃ i liá»‡u Ä‘Ã£ náº¡p
"""
        await cl.Message(content=help_msg).send()
        return
    
    if user_input.lower().startswith("/delete "):
        file_id = user_input[8:].strip()
        try:
            delete_file(file_id)
            await cl.Message(content=f"ğŸ—‘ï¸ ÄÃ£ xÃ³a file: `{file_id}`").send()
        except Exception as e:
            await cl.Message(content=f"âŒ Lá»—i khi xÃ³a file: {str(e)}").send()
        return
    
    # Ignore empty messages
    if not user_input:
        return
    
    # Check if there are any documents
    files = list_files()
    if not files:
        await cl.Message(
            content="âš ï¸ ChÆ°a cÃ³ tÃ i liá»‡u nÃ o Ä‘Æ°á»£c náº¡p. Vui lÃ²ng Ä‘Ã­nh kÃ¨m file PDF/TXT Ä‘á»ƒ báº¯t Ä‘áº§u."
        ).send()
        return
    
    # Create response message
    msg = cl.Message(content="")
    await msg.send()
    
    try:
        # Get answer
        result = await asyncio.to_thread(sync_process_query, user_input)
        
        answer = result["answer"]
        context = result["context"]
        metadatas = result["metadatas"]
        
        # Update message with answer
        msg.content = answer
        
        # Show context as expandable elements
        if context:
            elements = []
            for i, (doc, meta) in enumerate(zip(context, metadatas)):
                source = meta.get("source", "Unknown")
                chunk_idx = meta.get("chunk_index", i)
                
                # Create text element for context
                elements.append(
                    cl.Text(
                        name=f"ğŸ“– Nguá»“n {i+1}: {source} (chunk {chunk_idx})",
                        content=doc,
                        display="side"
                    )
                )
            
            msg.elements = elements
        
        await msg.update()
        
        # Update history
        history = cl.user_session.get("history", [])
        history.append({"role": "user", "content": user_input})
        history.append({"role": "assistant", "content": answer})
        cl.user_session.set("history", history)
        
    except Exception as e:
        msg.content = f"âŒ ÄÃ£ xáº£y ra lá»—i: {str(e)}"
        await msg.update()
